{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from core.tiny import GPTSimple\n",
    "from core.train import GPTSimpleTrainer\n",
    "from core.config import GPT1Config\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CodeParrot dataset\n",
    "# dataset = load_dataset(\"codeparrot/github-code\", streaming=True, languages=[\"Python\"])\n",
    "\n",
    "# Set up the DataLoader for the training data\n",
    "train_dataset = load_dataset(\"huggingface-course/codeparrot-ds-train\", streaming=True, split=\"train\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "\n",
    "# Set up the DataLoader for the validation data\n",
    "valid_dataset = load_dataset(\"huggingface-course/codeparrot-ds-valid\", streaming=True, split=\"validation\")\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
    "\n",
    "# Define the GPTSimple model and the optimizer\n",
    "config = GPT1Config(vocab_size=50257, max_len=512)\n",
    "model = GPTSimple(config)\n",
    "\n",
    "# Set up the PyTorch Lightning trainer\n",
    "logger = TensorBoardLogger(\"logs\", name=\"gpt-simple\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    callbacks=[pl.callbacks.EarlyStopping(monitor=\"val_loss\")],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader, valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MyDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/code/learning/MiniGPT/notebooks/basic.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/root/code/learning/MiniGPT/notebooks/basic.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader, random_split\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/root/code/learning/MiniGPT/notebooks/basic.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load your dataset and split it into train and validation sets\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/root/code/learning/MiniGPT/notebooks/basic.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m dataset \u001b[39m=\u001b[39m MyDataset()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/root/code/learning/MiniGPT/notebooks/basic.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m train_dataset, val_dataset \u001b[39m=\u001b[39m random_split(dataset, [\u001b[39m90\u001b[39m, \u001b[39m10\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/root/code/learning/MiniGPT/notebooks/basic.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MyDataset' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Load your dataset and split it into train and validation sets\n",
    "dataset = MyDataset()\n",
    "train_dataset, val_dataset = random_split(dataset, [90, 10])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Initialize the model and trainer\n",
    "model = GPTSimple(config)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,              # If you have a GPU, specify the number of GPUs to use here.\n",
    "    max_epochs=10,       # Number of epochs to train for.\n",
    ")\n",
    "\n",
    "# Create a GPTSimpleTrainer object and pass it to the trainer\n",
    "gpt_trainer = GPTSimpleTrainer(model, lr=1e-3)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=10,\n",
    ")\n",
    "trainer.fit(gpt_trainer, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration wikitext-2-raw-v1-a91abae62a73f102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/wikitext-2-raw-v1 to /root/.cache/huggingface/datasets/text/wikitext-2-raw-v1-a91abae62a73f102/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008911c508254f74a51466c9a62caa9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a12a5805fe4e34832df78f6a70e220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9d6c9302f14542b541225b22fc2278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/wikitext-2-raw-v1-a91abae62a73f102/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d84104d64b43cc9c4b903f500ab332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the preprocessed GPT-2 dataset from Hugging Face.\n",
    "dataset = load_dataset('text', 'wikitext-2-raw-v1')\n",
    "# Get the text data as a list of strings.\n",
    "text_data = dataset['train']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/exp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# Create a dataloader for the text dataset\n",
    "train_dataloader = DataLoader(\n",
    "    text_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=10,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GPT1Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/code/learning/MiniGPT/notebooks/basic.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/root/code/learning/MiniGPT/notebooks/basic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Define the GPTSimple model and the optimizer\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/root/code/learning/MiniGPT/notebooks/basic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m config \u001b[39m=\u001b[39m GPT1Config(vocab_size\u001b[39m=\u001b[39m\u001b[39m50257\u001b[39m, max_len\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/root/code/learning/MiniGPT/notebooks/basic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m GPTSimple(config)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/root/code/learning/MiniGPT/notebooks/basic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/root/code/learning/MiniGPT/notebooks/basic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     gpus\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,              \u001b[39m# If you have a GPU, specify the number of GPUs to use here.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/root/code/learning/MiniGPT/notebooks/basic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,       \u001b[39m# Number of epochs to train for.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/root/code/learning/MiniGPT/notebooks/basic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GPT1Config' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the GPTSimple model and the optimizer\n",
    "config = GPT1Config(vocab_size=50257, max_len=512)\n",
    "model = GPTSimple(config)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,              # If you have a GPU, specify the number of GPUs to use here.\n",
    "    max_epochs=10,       # Number of epochs to train for.\n",
    ")\n",
    "\n",
    "# Create a GPTSimpleTrainer object and pass it to the trainer\n",
    "gpt_trainer = GPTSimpleTrainer(model, lr=1e-3)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    accelerator=['cpu'],\n",
    "    max_epochs=10,\n",
    ")\n",
    "trainer.fit(gpt_trainer, train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices, 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"devices,\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e83ec8dcf0b5679deb55b7d5613794b95abb2df0860752b19e6f08ac0cb49c75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
