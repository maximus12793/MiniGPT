{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mroq/opt/miniconda3/envs/exp/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from core.tiny import GPTSimple\n",
    "from core.config import GPT1Config\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration huggingface-course--codeparrot-ds-train-7e9fc5dfe436a81a\n",
      "Using custom data configuration huggingface-course--codeparrot-ds-valid-65557c3279496c87\n",
      "/Users/mroq/opt/miniconda3/envs/exp/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:474: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`CUDAAccelerator` can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m# Set up the PyTorch Lightning trainer\u001b[39;00m\n\u001b[1;32m     17\u001b[0m logger \u001b[39m=\u001b[39m TensorBoardLogger(\u001b[39m\"\u001b[39m\u001b[39mlogs\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-simple\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mTrainer(\n\u001b[1;32m     19\u001b[0m     gpus\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     20\u001b[0m     max_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     21\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[pl\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(monitor\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m)],\n\u001b[1;32m     22\u001b[0m     logger\u001b[39m=\u001b[39;49mlogger,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m     26\u001b[0m trainer\u001b[39m.\u001b[39mfit(model, train_loader, valid_loader)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/exp/lib/python3.9/site-packages/pytorch_lightning/utilities/argparse.py:348\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m    347\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/exp/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:420\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, logger, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, inference_mode)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m DataConnector(\u001b[39mself\u001b[39m, multiple_trainloader_mode)\n\u001b[0;32m--> 420\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m AcceleratorConnector(\n\u001b[1;32m    421\u001b[0m     num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[1;32m    422\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[1;32m    423\u001b[0m     tpu_cores\u001b[39m=\u001b[39;49mtpu_cores,\n\u001b[1;32m    424\u001b[0m     ipus\u001b[39m=\u001b[39;49mipus,\n\u001b[1;32m    425\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[1;32m    426\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    427\u001b[0m     gpus\u001b[39m=\u001b[39;49mgpus,\n\u001b[1;32m    428\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[1;32m    429\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[1;32m    430\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[1;32m    431\u001b[0m     replace_sampler_ddp\u001b[39m=\u001b[39;49mreplace_sampler_ddp,\n\u001b[1;32m    432\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    433\u001b[0m     auto_select_gpus\u001b[39m=\u001b[39;49mauto_select_gpus,\n\u001b[1;32m    434\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[1;32m    435\u001b[0m     amp_type\u001b[39m=\u001b[39;49mamp_backend,\n\u001b[1;32m    436\u001b[0m     amp_level\u001b[39m=\u001b[39;49mamp_level,\n\u001b[1;32m    437\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[1;32m    438\u001b[0m )\n\u001b[1;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m LoggerConnector(\u001b[39mself\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/exp/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:204\u001b[0m, in \u001b[0;36mAcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_gpu_accelerator_backend()\n\u001b[0;32m--> 204\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_parallel_devices_and_init_accelerator()\n\u001b[1;32m    206\u001b[0m \u001b[39m# 3. Instantiate ClusterEnvironment\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_environment: ClusterEnvironment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_and_init_cluster_environment()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/exp/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:561\u001b[0m, in \u001b[0;36mAcceleratorConnector._set_parallel_devices_and_init_accelerator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m accelerator_cls\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m    556\u001b[0m     available_accelerator \u001b[39m=\u001b[39m [\n\u001b[1;32m    557\u001b[0m         acc_str\n\u001b[1;32m    558\u001b[0m         \u001b[39mfor\u001b[39;00m acc_str \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_types\n\u001b[1;32m    559\u001b[0m         \u001b[39mif\u001b[39;00m AcceleratorRegistry[acc_str][\u001b[39m\"\u001b[39m\u001b[39maccelerator\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mis_available()\n\u001b[1;32m    560\u001b[0m     ]\n\u001b[0;32m--> 561\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    562\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00maccelerator_cls\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` can not run on your system\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m since the accelerator is not available. The following accelerator(s)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is available and can be passed into `accelerator` argument of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `Trainer`: \u001b[39m\u001b[39m{\u001b[39;00mavailable_accelerator\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_devices_flag_if_auto_passed()\n\u001b[1;32m    570\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_devices_flag \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `CUDAAccelerator` can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu']."
     ]
    }
   ],
   "source": [
    "# Load the CodeParrot dataset\n",
    "# dataset = load_dataset(\"codeparrot/github-code\", streaming=True, languages=[\"Python\"])\n",
    "\n",
    "# Set up the DataLoader for the training data\n",
    "train_dataset = load_dataset(\"huggingface-course/codeparrot-ds-train\", streaming=True, split=\"train\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "\n",
    "# Set up the DataLoader for the validation data\n",
    "valid_dataset = load_dataset(\"huggingface-course/codeparrot-ds-valid\", streaming=True, split=\"validation\")\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
    "\n",
    "# Define the GPTSimple model and the optimizer\n",
    "config = GPT1Config(vocab_size=50257, max_len=512)\n",
    "model = GPTSimple(config)\n",
    "\n",
    "# Set up the PyTorch Lightning trainer\n",
    "logger = TensorBoardLogger(\"logs\", name=\"gpt-simple\")\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=10,\n",
    "    callbacks=[pl.callbacks.EarlyStopping(monitor=\"val_loss\")],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader, valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e83ec8dcf0b5679deb55b7d5613794b95abb2df0860752b19e6f08ac0cb49c75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
